{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import msprime, tskit\n",
    "# import tsinfer, tsdate\n",
    "# from IPython.display import SVG\n",
    "# import cyvcf2\n",
    "# import json\n",
    "# import matplotlib.pyplot as plt\n",
    "# import cyvcf2 # For reading VCF files into Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Tree sequence inference and statistics\n",
    "\n",
    "So far, we've focused on *simulating* data with a tree sequence structure, and we've talked about the benefits of doing so. We've looked at some basic summary statistics of the tree sequences to try and interpret them, but you might be wondering,\n",
    " - So far we've been doing all this on simulated datasets. Can I use any of these techniques on my real dataset?\n",
    "  - what if I want to perform 'conventional' analyses on these? Do I need to convert my tree sequences out to VCFs and then apply all my regular tools, or can I do any of these analyses directly on the tree sequence files?\n",
    "\n",
    "In both cases, the answer is Yes! \n",
    "\n",
    "1. The `tsinfer` and `tsdate` packages let you estimate a tree sequence for your dataset. (Note: these are *estimates* -- they won't be exactly correct. See Brandt et al for some discussion of these, and what types of information may or may not be legit for these)\n",
    "2. The `tskit` package (which we've already seen and used) has a number of utility functions that let you explore, manipulate and analyse data stored in a tree sequence format. \n",
    "\n",
    "In this notebook, we'll touch on all of these to give you a flavour of what is possible with these packages.\n",
    "\n",
    " - [4.1 An overview of tsinfer](#5.1Overview)\n",
    " - [4.2 Hands on with tsinfer](#5.2HandsOn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cyvcf2 # For reading VCF files into Python\n",
    "\n",
    "import tskit\n",
    "import tsinfer, tsdate\n",
    "from IPython.display import SVG\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5.1Overview'></a>\n",
    "## 4.1 An overview of `tsinfer`\n",
    "\n",
    "Simulating a tree sequence is relatively simple compared to *inferring* a tree sequence from existing data.\n",
    "The [tsinfer software](https://tsinfer.readthedocs.io/en/stable/) implements a heuristic algorithm which does this in a scalable manner.\n",
    "\n",
    "`Tsinfer` (pronounced t-s-infer) is comparable in some ways to other ancestral inference software such as [ARGweaver](https://doi.org/10.1371/journal.pgen.1004342), [Relate](https://myersgroup.github.io/relate/), and [Rent+](https://doi.org/10.1093/bioinformatics/btw735). However, it differs considerably in approach and scalability.\n",
    "Note that none of these other software packages produce tree sequences as output, although is possible to convert their output to tree sequences.\n",
    "Also note that `tsinfer` produces trees with a relatively accurate topology, but unlike other ancestral inference tools, it makes no attempt at the moment to produce precise branch length estimates -- for this we need another tool like `tsdate`.\n",
    "\n",
    "An important restriction is that `tsinfer` requires phased sample sequences with known ancestral states for each variant. It also works better with full sequence data than with data from scattered target SNPs (e.g. as obtained from SNP chips)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We'll be looking at a dataset of variants from sparrow chromosome 24 kindly shared by Mark Ravinet. There are 10 individuals represented in the samples: 5 from Norway and 5 from France.\n",
    "\n",
    "### 5.1.1 Preparing the data for `tsinfer`\n",
    "\n",
    "To prepare our data for `tsinfer`,\n",
    "we need to make a `SampleData` object with information about the individuals and phased, bi-allelic sites we wish to use for inference.\n",
    "\n",
    "These things are typically done with the `add_individual()` and `add_sites()` methods.\n",
    "To save us some time, let's define some helper functions (taken from the tsinfer website) that will make this object for us from a `cyvcf2` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions for importing data from VCF --> tsinfer format.\n",
    "# Properties these functions preserve:\n",
    "# - Our data is diploid\n",
    "# - Our individuals belong to two distinct populations, and we want our sample data to include that information.\n",
    "# - we only want the inference to use alleles at SNVs and deletions for now (others are possible!)\n",
    "\n",
    "def add_diploid_sites(vcf, samples):\n",
    "    \"\"\"\n",
    "    Read the sites in the vcf and add them to the samples object.\n",
    "    \"\"\"\n",
    "    # You may want to change the following line, e.g. here we allow\n",
    "    # \"*\" (a spanning deletion) to be a valid allele state\n",
    "    allele_chars = set(\"ATGCatgc*\")\n",
    "    pos = 0\n",
    "    # progressbar = tqdm(total=samples.sequence_length, desc=\"Read VCF\", unit='bp')\n",
    "    for variant in vcf:  # Loop over variants, each assumed at a unique site\n",
    "        # progressbar.update(variant.POS - pos)\n",
    "        if pos == variant.POS:\n",
    "            print(f\"Duplicate entries at position {pos}, ignoring all but the first\")\n",
    "            continue\n",
    "        else:\n",
    "            pos = variant.POS\n",
    "        if any([not phased for _, _, phased in variant.genotypes]):\n",
    "            raise ValueError(\"Unphased genotypes for variant at position\", pos)\n",
    "        alleles = [variant.REF.upper()] + [v.upper() for v in variant.ALT]\n",
    "        ancestral = variant.INFO.get(\"AA\", \".\")  # \".\" means unknown\n",
    "        # some VCFs (e.g. from 1000G) have many values in the AA field: take the 1st\n",
    "        ancestral = ancestral.split(\"|\")[0].upper()\n",
    "        if ancestral == \".\" or ancestral == \"\":\n",
    "            ancestral_allele = tskit.MISSING_DATA\n",
    "            # alternatively, you could specify `ancestral = variant.REF.upper()`\n",
    "        else:\n",
    "            ancestral_allele = alleles.index(ancestral)\n",
    "        # Check we have ATCG alleles\n",
    "        for a in alleles:\n",
    "            if len(set(a) - allele_chars) > 0:\n",
    "                print(f\"Ignoring site at pos {pos}: allele {a} not in {allele_chars}\")\n",
    "                continue\n",
    "        # Map original allele indexes to their indexes in the new alleles list.\n",
    "        genotypes = [g for row in variant.genotypes for g in row[0:2]]\n",
    "        samples.add_site(pos, genotypes, alleles, ancestral_allele=ancestral_allele)\n",
    "\n",
    "\n",
    "def chromosome_length(vcf):\n",
    "    assert len(vcf.seqlens) == 1\n",
    "    return vcf.seqlens[0]\n",
    "\n",
    "def add_populations(vcf, samples):\n",
    "    \"\"\"\n",
    "    Add tsinfer Population objects and returns a list of IDs corresponding to the VCF samples.\n",
    "    \"\"\"\n",
    "    # In this VCF, the first letter of the sample name refers to the population\n",
    "    samples_first_letter = [sample_name[0] for sample_name in vcf.samples]\n",
    "    pop_lookup = {}\n",
    "    pop_lookup[\"8\"] = samples.add_population(metadata={\"country\": \"Norway\"})\n",
    "    pop_lookup[\"F\"] = samples.add_population(metadata={\"country\": \"France\"})\n",
    "    return [pop_lookup[first_letter] for first_letter in samples_first_letter]\n",
    "\n",
    "\n",
    "def add_diploid_individuals(vcf, samples, populations):\n",
    "    for name, population in zip(vcf.samples, populations):\n",
    "        samples.add_individual(ploidy=2, metadata={\"name\": name}, population=population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use these helper functions to read in information about our sparrow sample from the VCF file and save it into a `tsinfer.SampleData` object.\n",
    "First, we add in information about our populations.\n",
    "Then we add information about the sampled individuals in those populations,\n",
    "and finally then add the genotypes held by those individuals at each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W::bcf_hrec_check] Missing ID attribute in one or more header lines\n",
      "[W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String\n",
      "[W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'\n",
      "/Users/georgia/micromamba/envs/2025-ts-workshops/lib/python3.12/site-packages/tsinfer/formats.py:458: FutureWarning: The LMDBStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "  return zarr.LMDBStore(self.path, subdir=False, map_size=map_size)\n",
      "/Users/georgia/micromamba/envs/2025-ts-workshops/lib/python3.12/site-packages/tsinfer/formats.py:428: FutureWarning: The LMDBStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "  store = zarr.LMDBStore(\n"
     ]
    }
   ],
   "source": [
    "vcf_location = \"P_dom_chr24_phased.vcf.gz\"\n",
    "vcf = cyvcf2.VCF(vcf_location)\n",
    "with tsinfer.SampleData(\n",
    "    path=\"P_dom_chr24_phased.samples\", sequence_length=chromosome_length(vcf)\n",
    ") as samples:\n",
    "    populations = add_populations(vcf, samples)\n",
    "    add_diploid_individuals(vcf, samples, populations)\n",
    "    add_diploid_sites(vcf, samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample file created for 20 samples (10 individuals) with 13192 variable sites.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Sample file created for {} samples \".format(samples.num_samples)\n",
    "    + \"({} individuals) \".format(samples.num_individuals)\n",
    "    + \"with {} variable sites.\".format(samples.num_sites),\n",
    "    flush=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Inferring a tree sequence with `tsinfer` and `tsdate`\n",
    "\n",
    "Importing the data into a tsinfer-ready format was the hardest part -- the next thing is to run tsinfer. \n",
    "\n",
    "(note to self: should mention mismatch ratio here somewhere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_undated = tsinfer.infer(samples)\n",
    "\n",
    "ts_undated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! We now have a bona-fide tree sequence holding our data that we can inspect, analyse and manipulate in all the ways we have done previously. \n",
    "\n",
    "Do you notice anything different about this tree sequence compared with the simulated ones that we've been working with previously? \n",
    "1. As usual, there's some useful information about the fact that we generated this with tsinfer in the provenance section of the table. Note that you can click through and see all the parameters etc used.\n",
    "2. Secondly, \"Time Units: uncalibrated\". That's because tsinfer infers the topologies for these trees, but doesn't infer times for them (and in fact, takes no informarion about mutation rates or coalescence times or anything else that could help to estimate this.). For this, we'll apply `tsdate`.\n",
    "3. A more subtle one: more sites than mutations. This happens because, in the process of generating the trees, tsinfer also generates a bunch of ancestral haplotypes and that *don't* end up contributing info to the final genotypes we see.\n",
    "\n",
    "We'll deal with these second two problems one a time.\n",
    "\n",
    "First, we'll apply `simplify()` to remove some 'stray' unary nodes and sites outputted by tsinfer -- this 'pruning' step removes all elements of the inferred tree sequence other than those needed to represent the genotypes of the samples.\n",
    "After this, we'll run `tsdate` to obtain a time-calibrated version of this inferred tree sequence using an estimated mutation rate of `1e-8` per base per generation.\n",
    "\n",
    "(Can this be altered?)\n",
    "\n",
    " (Also, see [this function](https://tskit.dev/tsdate/docs/latest/python-api.html#preprocessing-tree-sequences) for some other useful pre-processing functions one can use on the tree sequence -- excluding samples from data poor regions e.g. near the telomeres, or excluding particular samples.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutation rate is given as the probability of mutations per base per generation\n",
    "tss = ts_undated.simplify()\n",
    "ts_dated = tsdate.date(tss, mutation_rate=1e-8)\n",
    "\n",
    "ts_dated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each of these steps has added an extra row into the provenance table too.\n",
    "\n",
    "We're getting close to the point where printing individual trees might be a little overwhelming and hard to interpret. (tsbrowse), on the web, provides a number of useful functions that shows you some other visualisations of these trees that might be especially big for these larger datasets. \n",
    "\n",
    "Let's print some trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = {\"Norway\": \"red\", \"France\": \"blue\"}\n",
    "colours_for_node = {}\n",
    "for n in ts_dated.samples():\n",
    "    population_data = ts_dated.population(ts_dated.node(n).population)\n",
    "    colours_for_node[n] = colours[json.loads(population_data.metadata)[\"country\"]]\n",
    "\n",
    "individual_for_node = {}\n",
    "for n in ts_dated.samples():\n",
    "    individual_data = ts_dated.individual(ts_dated.node(n).individual)\n",
    "    individual_for_node[n] = json.loads(individual_data.metadata)[\"name\"]\n",
    "\n",
    "tree = ts_dated.at(4e6)\n",
    "tree.draw(\n",
    "    height=700,\n",
    "    width=1200,\n",
    "    node_labels=individual_for_node,\n",
    "    node_colours=colours_for_node\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of these samples are clustering by population label, but not all of them are. Let's look at another tree at a different position where there even fewer sample nodes are clustering by population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ts_dated.at(2e6)\n",
    "tree.draw(\n",
    "    path=\"tree_at_1Mb.svg\",\n",
    "    height=700,\n",
    "    width=1200,\n",
    "    node_labels=individual_for_node,\n",
    "    node_colours=colours_for_node,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. This one is less clear.\n",
    "\n",
    "The amount we can learn from any individual tree is perhaps limited, because of the stochasticity of the trees across the genome.\n",
    "\n",
    "Can we think of some way to summarise whether the Norwegian and French sparrows exhibit population structure, and learn more about the nature of that structure?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Summary statistics with tskit\n",
    "\n",
    "Suppose you have $n$ sequences typed at $m$ different sites...\n",
    "\n",
    "```\n",
    "   ...GTAACGCGATAAGAGATTAGCCCAAAAACACAGACATGGAAATAGCGTA...\n",
    "   ...GTAACGCGATAAGAGATTAGCCCAAAAACACAGACATGGAAATAGCGTA...\n",
    "   ...GTAACGCGATAAGATATTAGCCCAAAAACACAGACATGGAAATAGCGTA...\n",
    "   ...GTAACGCGATAAGATATTAGCCCAAAAACACAGACATGGAAATAGCGTA...\n",
    "   ...GTAACGCGATAAGATATTAGCCCAAAAACACAGACATGGAAATAGCGTA...\n",
    "   ...GTAACGCGATAAGATATTAGCCCAAAAACACAGACATGGTAATAGCGTA...\n",
    "   ...GTAACGCGATAAGATATTAGCCCAAAAACACAGACATGGTAATAGCGTA...\n",
    "```\n",
    "\n",
    "...and you want to calculate mean pairwise diversity on these samples, i.e.\n",
    "\n",
    "$$ \\pi = \\dfrac{1}{n(n-1)/2}\\sum_{i=1}^{n-1} \\sum_{j=i+1}^n k_{ij}, $$\n",
    "\n",
    "where $k_{ij}$ is the number of sites at which sequences $i$ and $j$ carry a different allele.\n",
    "The scaling of this procedure is\n",
    "\n",
    "$$ O\\left( n^2 m \\right) $$\n",
    "\n",
    "ie. quadratic in the number of samples $n$, and linear in the number of sites $m$.\n",
    "However, there is an equivalent way of performing this calculation by assigning weights to the sample nodes, and propagating these values further up the tree using a 'summary function' at each mutation.\n",
    "\n",
    " <img src=\"pics/worksheet4-node-weights.jpeg\" width=\"350\" height=\"350\">\n",
    " \n",
    " This is what `tskit` calls a *site statistic* calculation, and because the operation is of order\n",
    " \n",
    " $$ O\\left( n + \\rho m (\\log(n))^2 \\right)  << O\\left( n^2 m \\right), $$\n",
    " \n",
    "the calculation is quick to run, especially on large datasets:\n",
    "\n",
    " <img src=\"pics/worksheet4-stat-speed.jpeg\" width=\"500\" height=\"500\">\n",
    "\n",
    "This is what `tskit` calls a *site statistic* calculation, and because the operation is of order\n",
    " \n",
    " $$ O\\left( n + \\rho m (\\log(n))^2 \\right)  << O\\left( n^2 m \\right), $$\n",
    " \n",
    "the calculation is quick to run, especially on large datasets:\n",
    "\n",
    " <img src=\"pics/worksheet4-stat-speed.jpeg\" width=\"500\" height=\"500\">\n",
    "\n",
    "See the following paper for more details.\n",
    "\n",
    "Peter Ralph, Kevin Thornton, Jerome Kelleher, Efficiently Summarizing Relationships in Large Samples: A General Duality Between Statistics of Genealogies and Genomes, Genetics, Volume 215, Issue 3, 1 July 2020, Pages 779â€“797, https://doi.org/10.1534/genetics.120.303253"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The basic syntax: (nucleotide diversity)\n",
    "\n",
    "`tskit` uses very similar syntax for all of its inbuilt statistics, so we'll explore the options using `diversity()` as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts_dated.diversity())\n",
    "print(ts_dated.diversity(sample_sets = [ts_dated.samples(0), ts_dated.samples(1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts_dated.divergence(sample_sets=[ts_dated.samples(0), ts_dated.samples(1)]))\n",
    "print(ts_dated.divergence(sample_sets=[ts_dated.samples(0), ts_dated.samples(0)]))\n",
    "print(ts_dated.divergence(sample_sets=[ts_dated.samples(1), ts_dated.samples(1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fst = ts_dated.Fst(sample_sets=[ts_dated.samples(0), ts_dated.samples(1)])\n",
    "\n",
    "print(Fst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, $F_{st}$ the the proportion of the total genetic variance that can be attributed to genetic variance within populations. (Closer to 0 --> less differentiation, closer to 1 -- more)\n",
    "\n",
    "This is pretty small, but we also have high dispersal rates (and potentially large effective population sizes.)\n",
    "\n",
    "So, yes, more difference between average pairs of individuals of different populations than between the sample populations.\n",
    "Would also guess from this that the second population is a bit bigger (has larger Ne) than the first.\n",
    "\n",
    "(Not actually doing inference with this -- but maybe get some suggested ideas.)\n",
    "\n",
    "A second question -- when, in time, did this split happen approximately?\n",
    "Would like to know something like -- for each ancestral node, how many present-day descendants are Norwegian versus French?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dated = ts_dated.simplify()\n",
    "mean_desc = ts_dated.mean_descendants([ts_dated.samples(0), ts_dated.samples(1)])\n",
    "\n",
    "print(mean_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row is a node (haplotype) that is ancestral to the sample, and the columns list the number of samples from each population.\n",
    "\n",
    "Let's calculate the different between this value and 50%;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each row of mean_desc, calculate the absolute value of the difference between the two columns divided by the sum of the two columns\n",
    "diff_in_anc = []\n",
    "\n",
    "for row in mean_desc:\n",
    "    diff_in_anc.append(abs(row[0] - row[1]) / (row[0] + row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_in_anc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diff_in_anc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# make a scatterplot of diff_in_anc (on y axis) and nodes.tables.time (on x axis)\n",
    "plt.scatter(np.log10(ts_dated.tables.nodes.time), diff_in_anc, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a smaller, neater  version of this first.\n",
    "If we pull out all of the nodes that have 10 descendants, when does the standard deviation of the number of blue descedants (approximately) match what you'd expect from a binomial distribution?\n",
    "\n",
    "First, let's extract all of the nodes with 10 leaves in the tree. We can do this with the `mean_desc` object we created before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_descendants = mean_desc.sum(axis=1).astype(int)\n",
    "print(num_descendants.shape)\n",
    "\n",
    "print(num_descendants)\n",
    "ids_10 = np.where(num_descendants == 10)\n",
    "\n",
    "print(ids_10)\n",
    "\n",
    "total_ancestral_nodes = 0\n",
    "for n in range(0, 21):\n",
    "\n",
    "    ids = np.where(num_descendants == n)\n",
    "    total_ancestral_nodes += len(ids[0])\n",
    "\n",
    "print(total_ancestral_nodes)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to extract the values of `mean_desc` and `time` for each of these\n",
    "\n",
    "wow, this is confusing because everything is not an integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_nodes = np.where(num_descendants == 4)[0]\n",
    "focal_mean_desc = mean_desc[focal_nodes]\n",
    "focal_times = ts_dated.tables.nodes.time[focal_nodes]\n",
    "\n",
    "print(focal_mean_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot focal_mean_desc (on y axis) and focal_times (on x axis)\n",
    "plt.scatter(focal_times[:-1], focal_mean_desc[:-1, 0], label=\"Population 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recent descendants and introgressed tracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at individual = \"8934547\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ts_dated.at(2e6)\n",
    "tree.draw(\n",
    "    height=700,\n",
    "    width=1500,\n",
    "    node_labels=individual_for_node,\n",
    "    node_colours=colours_for_node,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ts_dated.at(4e6)\n",
    "tree.draw(\n",
    "    height=700,\n",
    "    width=1500,\n",
    "    node_labels=individual_for_node,\n",
    "    node_colours=colours_for_node,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnns  = ts_dated.genealogical_nearest_neighbours(\n",
    "    focal = [0],\n",
    "    sample_sets = [ts_dated.samples(0), ts_dated.samples(1)]\n",
    ")\n",
    "\n",
    "print(gnns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = ts_dated.genetic_relatedness_matrix(\n",
    "    sample_sets = [ts_dated.samples(0), ts_dated.samples(1)] \n",
    ")\n",
    "\n",
    "print(gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_nearest_neighbour_populations(t, focal_sample):\n",
    "    \"\"\"\n",
    "    Find the nearest neighbour populations for a given focal sample.\n",
    "    \"\"\"\n",
    "    p = t.parent(focal_sample)\n",
    "    if p == -1:\n",
    "        return (0, 0)\n",
    "    children = [c for c in t.leaves(u = p) if c != focal_sample]\n",
    "    relative_populations = [ts_dated.node(c).population for c in children]  \n",
    "    # Calculate the proportion of children in each population\n",
    "    pop_proportions = {}\n",
    "    for pop in relative_populations:\n",
    "        if pop not in pop_proportions:\n",
    "            pop_proportions[pop] = 0\n",
    "        pop_proportions[pop] += 1\n",
    "    # Count how many of the items in relative_populations are 0\n",
    "    count_pop_0 = sum(1 for pop in relative_populations if pop == 0)\n",
    "    count_pop_1 = len(relative_populations) - count_pop_0\n",
    "    # Calculate proportion of children in each population\n",
    "    prop_pop_0 = count_pop_0 / len(relative_populations)\n",
    "    prop_pop_1 = count_pop_1 / len(relative_populations)\n",
    "\n",
    "    return prop_pop_0, prop_pop_1\n",
    "\n",
    "\n",
    "# test\n",
    "t = ts_dated.at(3.49e6)\n",
    "focal_sample = 0\n",
    "\n",
    "print(find_nearest_neighbour_populations(t, focal_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interval(t, focal_sample, seq_length, ax):\n",
    "    nns = find_nearest_neighbour_populations(t, focal_sample)\n",
    "    i = t.interval\n",
    "    ax.add_patch(plt.Rectangle((i[0]/seq_length, 0), (i[1] - i[0])/seq_length, nns[0], color=\"red\"))\n",
    "    ax.add_patch(plt.Rectangle((i[0]/seq_length, nns[0]), (i[1] - i[0])/seq_length, nns[0] + nns[1], color=\"blue\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ts_dated.individuals():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_proportions_for_individual(tree_seq, individual_id):\n",
    "\n",
    "    for i in tree_seq.individuals():\n",
    "        if i.id == individual_id:\n",
    "            node1, node2 = i.nodes\n",
    "            break\n",
    "\n",
    "    seq_length = tree_seq.sequence_length\n",
    "\n",
    "    # Plot it all\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 2.5))\n",
    "    for ax in [ax1, ax2]:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_xticklabels([])\n",
    "    for t in tree_seq.trees(sample_lists=True):\n",
    "        plot_interval(t, node1, seq_length, ax1) # CHANGE focal sample\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_yticklabels([])\n",
    "    ax1.set_ylabel(\"Hap 1\")\n",
    "    # Repeat the process for the second focal node\n",
    "    for t in tree_seq.trees(sample_lists=True):\n",
    "        plot_interval(t, node2, seq_length, ax2) # CHANGE focal sample\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_yticklabels([])\n",
    "    ax2.set_ylabel(\"Hap 2\")\n",
    "\n",
    "    # Add legend\n",
    "    colors = ['red', 'blue']\n",
    "    labels = ['Norway', 'France']\n",
    "    handles = [plt.Rectangle((0, 0), 1, 1, color=color) for color in colors]\n",
    "    ax2.legend(handles, labels, loc='upper right', bbox_to_anchor=(1.2, 1.5))\n",
    "\n",
    "    # Add overall title\n",
    "    fig.suptitle(f\"Nearest neighbour populations, sample {individual_id}\", fontsize=16)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# test\n",
    "plot_proportions_for_individual(ts_dated, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_proportions_for_individual(ts_dated, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_proportions_for_individual(ts_dated, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_proportions_for_individual(ts_dated, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_proportions_for_individual(ts_dated, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_proportions_for_individual(ts_dated, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_proportions_for_individual(ts_dated, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_proportions_for_individual(ts_dated, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_proportions_for_individual(ts_dated, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_proportions_for_individual(ts_dated, 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
